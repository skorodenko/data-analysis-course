---
title: "Аналіз рекомендацій в Steam"
author: "Скороденко Дмитро"
header-includes:
    - \usepackage{fontspec}
    - \usepackage{polyglossia}
    - \setmainlanguage{ukrainian}
    - \setotherlanguage{english}
    - \newfontfamily{\cyrillicfont}{Iosevka}
    - \newfontfamily{\cyrillicfonttt}{Iosevka}
    - \newfontfamily{\cyrillicfontsf}{Iosevka}
output:
    pdf_document:
        latex_engine: xelatex
---

```{r, setup, include = FALSE}
library(tidyverse)
library(GGally)
library(fastqq)
library(boot)
library(stargazer)
library(lmtest)
library(car)
```

# Лабораторна №0 -- Вибір датасету --

Для проведення аналізу даних було обрано [датасет](https://www.kaggle.com/datasets/antonkozyriev/game-recommendations-on-steam),
який містить 10M+ записів про рекомендації комп'ютерних ігор користувачів платформи [Steam](https://store.steampowered.com/).
Оскільки в цьому датасеті зібрано дані про ігри які були випущені з 1997 по 2023 рік,
то його розмір не дасть змогу провести нормальний аналіз,
тому аналіз буде проводитись над іграми, які були випущені у 2020 - 2022 роках.

## Питання для дослідження:

1) За скільки ігрових годин в сердньому набирається перших 50% рев'ю (позитивних/негативних).
2) Яка середня ціна гри по кожному із рейтингів.
3) Залежність між рейтингом та цінами із високими знижками.
4) Зв'язок між кількістю рев'ю користувача і їх корисністю.
5) Зв'язок між кумедністю рев'ю та його корисністю.
6) Чи змінює початкову вартість гри підтримка `Mac`, `Linux (native)`.

## Гіпотези по дослідницьким питанням:

3) Ціни із високими знижками скоріше за все сприяють зменшенню рейтингу.
4) Можливо велика к-сть рев'ю може мати позитивний вплив на середню корисність рев'ю певного користувача.
5) Скоріше за все зв'язок між кумедністю та корисністю рев'ю - прямий (вища кумедність = вища корисність).
6) Підтримка додаткових платформ `Mac` та `Linux (native)` скоріше за все не змінює вартість гри.

## Короткий опис датасету:

Датасет містить 4 файли, далі наведено короткий опис кодного з них:

-   _games.csv_
    -   **app_id** - ід гри
    -   **title** - назва гри
    -   **date_release** - дата випуску гри
    -   **win** - підтримка гри на `Windows`
    -   **mac** - підтримка гри на `Mac`
    -   **linux** - підтримка гри на `Linux (native)`
    -   **rating** - рейтинг гри
    -   **positive_ratio** - відношення позитивних відгуків до всіх відгуків (у відсотках)
    -   **user_reviews** - кількість відгуків
    -   **price_final** - ціна зі знижками
    -   **price_original** - ціна при випускі гри
    -   **discount** - знижка (у відсотках)
    -   **steam_deck** - підтримка гри на `Steam Deck`
-   _recomendations.csv_
    -   **app_id** - ід гри
    -   **helpful** - к-сть користувачів, які сказали що рекомендація корисна
    -   **funny** - к-сть користувачів, які сказали що рекомендація дотепна
    -   **date** - дата публікації рекомендації
    -   **is_recommended** - чи рекомендує користувач дану гру
    -   **hours** - к-сть годин проведених у грі
    -   **user_id** - ід користувача
    -   **review_id** - ід рев'ю
-   _users.csv_
    -   **user_id** - ід користувача
    -   **products** - кількість куплених продуктів на платформі `Steam`
    -   **reviews** - к-сть рев'ю, які написав користувач
-   _games_metadata.json_
    -   Файл, що містить метаданні (теги, к-сть DLC ...). При аналізі даних використовуватись не буде

# Лабораторна №1 -- EDA --

```{r, data_import, include = FALSE}
games <- read_csv("data/games.csv")
recomendations <- read_csv("data/recommendations.csv")
users <- read_csv("data/users.csv")
```

## Підготовка даних

Дані в вибраному датасеті поділені на файли `users.csv`, `games.csv` та `recomendations.csv`. Остання є таблицею для зв'язку many to many. Для того щоб проводити подальшу роботу всі дані будуть об'єднані в одну таблицю.

```{r, table_join}
data <- inner_join(recomendations, games, by="app_id")
data <- inner_join(data, users, by="user_id")

rm(recomendations)
rm(games)
rm(users)

glimpse(data)
```

Далі відфільтруємо ігри які були випущені у 2020 - 2022 році.

```{r}
data <- data %>% filter(date_release > '2020-01-01')
data <- data %>% filter(date_release < '2023-01-01')
glimpse(data)
```

Далі перевіримо дані на `na`.

```{r}
data %>% is.na %>% colSums()
```

Датасет чистий.

Далі буде доцільно перекодувати колонку `rating`. Дані про кодування взято [тут](https://www.gamedeveloper.com/business/fixing-steam-s-user-rating-charts).

```{r}
rating <- case_match(
    data$rating,
    "Overwhelmingly Negative" ~ -4,
    "Very Negative" ~ -3,
    "Negative" ~ -2,
    "Mostly Negative" ~ -1,
    "Mixed" ~ 0,
    "Mostly Positive" ~ 1,
    "Positive" ~ 2,
    "Very Positive" ~ 3,
    "Overwhelmingly Positive" ~ 4
)
tmp <- tibble(rating = rating)
data <- data %>% select(-rating) %>% bind_cols(tmp)
data$rating %>% head(n=10)
```

Також можна прибрати колонку `title`, так як нас не цікавить назва гри, та змінити тип даних у деяких числових колонках.

```{r}
data <- data %>% select(-c(title))

data <- data %>%
    mutate(
        app_id = as.integer(app_id),
        user_id = as.integer(user_id),
        review_id = as.integer(review_id),
        helpful = as.integer(helpful),
        funny = as.integer(funny),
        user_reviews = as.integer(user_reviews),
        discount = as.integer(discount),
        products = as.integer(products),
        reviews = as.integer(reviews),
        rating = as.integer(rating),
        positive_ratio = as.integer(positive_ratio)
    )
```


\newpage

## Огляд числових характеристик

Оскільки початковий датасет включав зв'язок many to many, то огляд числових характеристик буде проводитись окремо для кожної сутності (`app`, `user`, `review`)

```{r}
data %>% distinct(app_id, .keep_all = TRUE) %>%
    select(
        app_id, date_release,
        rating, positive_ratio,
        user_reviews, price_final,
        price_original, discount,
        win, mac, linux, steam_deck
    ) %>%
    summary
```

```{r}
data %>% distinct(user_id, .keep_all = TRUE) %>%
    select(
        user_id, products,
        reviews
    ) %>%
    summary
```

```{r}
data %>% distinct(review_id, .keep_all = TRUE) %>%
    select(
        review_id, helpful, funny,
        date, hours, is_recommended
    ) %>%
    summary
```


\newpage

### Викиди

Очевидними кандидатами на перевірку викидів є `helpful`, `funny`, `products` та `hours`.

```{r, echo = FALSE, eval = TRUE}
data  %>% distinct(review_id, .keep_all = TRUE) %>% pull(helpful) %>% qqnorm(main = "Helpful qq plot")
data  %>% distinct(review_id, .keep_all = TRUE) %>% pull(hours) %>% qqnorm(main = "Hours qq plot")
data  %>% distinct(app_id, .keep_all = TRUE)  %>% pull(funny) %>% qqnorm(main = "Funny qq plot")
data  %>% distinct(app_id, .keep_all = TRUE)  %>% pull(user_reviews) %>% qqnorm(main = "Reviews qq plot")
data  %>% distinct(user_id, .keep_all = TRUE) %>% pull(products) %>% qqnorm(main = "Products qq plot")
```

У `funny` та `helpful` є викиди. Тому варто позбавитись їх.

```{r, echo = FALSE, message = FALSE}
data <- data %>%
    filter(funny < 500) %>%
    filter(helpful < 25000) %>%
    filter(user_reviews < 1000000) %>%
    filter(price_original < 100) %>%
    filter(price_final < 100)
```


\newpage

## Аналіз даних

-   **За скільки ігрових годин в сердньому набирається перших 50% рев'ю (позитивних/негативних)**

Для початку варто побудувати фацетовані графіки ігрових годин і кількостей позитивних/негативних рекомендацій.

```{r, message = FALSE, echo = FALSE, fig.cap = "Рекомендації відносно ігрових годин та виду реакції", eval = TRUE}
pdata <- data %>% group_by(hours, is_recommended) %>%
    summarise(recomendation_count = length(is_recommended))

pdata <- pdata %>%
    group_by(is_recommended) %>%
    mutate(csum = cumsum(recomendation_count)) %>%
    mutate(percent = csum/sum(recomendation_count))

ldata <- pdata %>%
    filter(percent < 0.5) %>%
    group_by(is_recommended) %>%
    summarise(
        mean_hours = mean(hours),
        critical_point = max(hours)
    )

pdata <- pdata %>%
    mutate_at(vars(matches("recomendation_count")), log)

ggplot(pdata, aes(x = hours, y = recomendation_count)) +
    geom_point(size = 0.05) +
    geom_vline(aes(xintercept = critical_point), ldata, colour="red") +
    labs(x = "In-game hours", y = "Log(Recomendation count)") +
    facet_wrap(~is_recommended, labeller = as_labeller(c("TRUE" = "Recomends", "FALSE" = "Not recomends")))
```

Стосовно даного графіку можна вказати 3 факти:

- В перші ігрові години ставиться багато рекомендацій (як позитивних так і негативних)
- В середньому навть на 1000-их годинах позитивниі рекомендації ставлять часто, а для негативних реакцій це рідкість.
- Для того щоб набрати 50% всіх рекомендацій знадобилось в середньому:

```{r, echo = FALSE, eval = TRUE}
knitr::kable(ldata, "simple")
```


\newpage

-   **Яка середня ціна гри по кожному із рейтингів**

Зообразимо розподіл ціни (`price_original`) відносно оціночних категорій (`rating`)

```{r, echo = FALSE, fig.cap = "Розподіл цін відносно оціночних категорій", eval = TRUE}
pdata <- data %>% distinct(app_id, .keep_all = TRUE) %>% select(price_original, rating)

ldata <- pdata %>%
    group_by(rating) %>%
    summarise(mean(price_original), n = length(price_original))

pdata$factor <- factor(x = pdata$rating,
                       levels = c(-4,-3,-2,-1,0,1,2,3,4))

ggplot(pdata, aes(x = factor, y = price_original)) +
    geom_boxplot() +
    labs(x = "Game rating", y = "Original price")
```

Категорії рейтингу лежать в межах інтервалу [-4,4], де 4 - це найвища оцінка.
Середні значення наведені далі:

```{r, echo = FALSE, eval = TRUE}
knitr::kable(ldata, "simple")
```


\newpage

-   **Залежність між рейтингом та ціною з високою знижкою**

Нанесемо на грфік відсоток позитивних відгуків (`positive_ratio`), фінальну ціну (`price_final`) та знижку (`discount`).
Також варто зазначити що величина `positive_ratio` напряму зв'язана з `rating`, однак остання є дискретною,
а на даному графіку краще неперевна величина.

Оскільки початкова гіпотеза вказує на те що високі знижки - ознака поганої гри,
знижки будуть відфільтровані відносно 3 квартилю.

```{r, echo = FALSE, fig.cap = "Відсоток позитивних відгуків відносно знижки та фінальної ціни", eval = TRUE}
pdata <- data %>%
    distinct(app_id, .keep_all = TRUE) %>%
    select(positive_ratio, price_final, discount) %>%
    arrange(discount) %>%
    filter(discount > 0)

quartile_3rd <- quantile(pdata$discount)[4]

pdata <- pdata %>% filter(discount >= quartile_3rd)

ggplot(pdata, aes(x = price_final, y = positive_ratio)) +
    geom_point(alpha=0.5) +
    geom_smooth(method=lm, color="red", se=TRUE) +
    labs(x = "Final price", y = "Positive ratio")
```

Даний графік чітко показує, що дане дослідне пиитання не є безпідставним.
Більша частина знижок знаходиться вище 70% позитивних відгуків.

Обрахуємо коефіцієнт кореляції

```{r, eval = TRUE}
coef <- cor(pdata$price_final, pdata$positive_ratio)
knitr::kable(coef, "simple")
```

Коефіцієнт кореляції від'ємний - тобто зв'язок є.
Початкову гіпотезу не відкидаєм.


\newpage

-   **Зв'язок між кількістю рев'ю користувача і їх корисністю**

Нанесемо на графік рев'ю (`reviews`) та ln корисністі (`helpfullness`) відносно кожного окремого користувача (`users`).

```{r, echo = FALSE, fig.cap = "Розподіли рев'ю та користності", eval = TRUE}
usertb <- data %>%
    group_by(user_id) %>%
    summarise(helpfullness = sum(helpful))

reviewtb <- data %>%
    distinct(user_id, .keep_all = TRUE) %>%
    select(user_id, reviews)

pdata <- inner_join(usertb, reviewtb, by="user_id")
pdata <- pdata %>% select(-c(user_id))

pdata <- pdata %>%
    filter(helpfullness > 0) %>%
    filter(reviews > 0)

coef <- cor(pdata$reviews, pdata$helpfullness)

pdata <- pdata %>%
    mutate_at(vars(matches("helpfullness")), log) %>%
    arrange(reviews)

ggplot(pdata, aes(x = reviews, y = helpfullness)) +
    geom_point(alpha=0.1) +
    xlab("User reviews") +
    ylab("Ln(helpfullness)")

knitr::kable(coef, "simple")
```

На графіку видно, що `reviews` та `ln(helpfullness)` не мають чіткої взаємодії.
Коефіцієнт кореляції != 0, тому питання потребує уточнення.


\newpage

-   **Зв'язок між кумедністю рев'ю та його корисністю**

Оскільки початкова гіпотеза вказує на прямий зв'язок між кумедністю та корисністю.
Просто обрахуємо коефіцієнт кореляції.

```{r, echo = FALSE, eval = TRUE}
pdata <- data %>%
    group_by(user_id) %>%
    summarise(
        helpful = sum(helpful),
        funny = sum(funny)
    )

coef <- cor(pdata$helpful, pdata$funny)
knitr::kable(coef, "simple")
```

Коефіцієнт кореляції > 0.5.
Початкову гіпотезу не відкидаєм.


\newpage

-   **Чи змінює підтримка гри на Mac, Linux (native) початкову вартість гри**

Спочатку важливо зрозуміти співвідношення між різними платформами. Варто зазначити, що є ще одна платформа `Steam Deck`, але вона фактично запускає ті самі ігри що і `Windows`.

```{r, echo = FALSE, fig.cap = "Співідношення між платформами", eval = TRUE}
pdata <- data %>%
    distinct(app_id, .keep_all = TRUE) %>%
    summarise(win = sum(win), mac = sum(mac), linux = sum(linux))

pie(
    c(pdata$win, pdata$mac, pdata$linux),
    labels = c("Windows", "Mac", "Linux (native)")
)
```

Так як доля `Linux (native)` + `Mac` майже чверть від усіх ігор на `Windows`,
то побудуємо гістограми розподілу цін.

\newpage

Будть розглянуті ціни відносно `Linux (native)` та/або `Mac`.

```{r, message = FALSE, echo = FALSE, fig.cap = "Ціна відносно платформи", eval = TRUE}
pdata <- data %>% distinct(app_id, .keep_all = TRUE)

pdata$winonly <- ifelse(pdata$mac | pdata$linux, FALSE, TRUE)

ggplot(pdata, aes(x=price_original, fill=winonly)) +
    geom_histogram(alpha=0.5, position = 'identity') +
    scale_fill_manual(values=c("#69b3a2", "#404080")) +
    labs(x="Price", y="Count")
```

Судячи із графіків в цілому ціни на ігри на `Mac` та/або `Linux (native)` як мінімум не перевищюють ціну гри на `Windows`.
Початкову гіпотезу не відкидаєм.


\newpage

## Висновки EDA

На основі проведеного розвідкового аналізу можна зробити наступні висновки:

- Всі дослідницькі питання залишаються актуальними.
    - Початкові дослідницькі питання що потребують уточнення:
        - За скільки ігрових годин в сердньому набирається перших 50% рев'ю (позитивних/негативних).
        - Яка середня ціна гри по кожному із рейтингів.
    - Початкові гіпотези, що потребують подальшого розгляду:
        - Можливо велика к-сть рев'ю може мати позитивний вплив на середню корисність рев'ю певного користувача.
        - Ціни із високими знижками скоріше за все сприяють зменшенню рейтингу.
        - Скоріше за все зв'язок між кумедністю та корисністю рев'ю - прямий (вища кумедність = вища корисність).
        - Підтримка додаткових платформ `Mac` та `Linux (native)` скоріше за все не змінює вартість гри.
    - Гіпотези після проведення EDA:
        - В сердньому 50% негативних рев'ю можуть збираються швидше ніж позитивні.
- Головним обмеженням даного аналізу є великий розмір датасету, однак використання спецальних бібліотек типу `fastqq` непогано вирішує це питання навіть без додаткованих обцислюючих потужностей.


\newpage

# Лабораторна №2 -- Статистичне виведення --

Далі всі уточнюючі обчислення будуть згруповані відносно відповідних дослідних питань.

```{r, message = FALSE, echo = FALSE, eval = TRUE}
options(pillar.sigfig = 8)
```

## Довірчі інтервали

-   **За скільки ігрових годин в сердньому набирається перших 50% рев'ю (позитивних/негативних)**

Обрахуємо довірчий інтервал для середніх, що мають **нормальний розподіл**.

```{r, message = FALSE, echo = FALSE, eval = TRUE}
alpha <- 0.05

pdata <- data %>% group_by(hours, is_recommended) %>%
    summarise(recomendation_count = length(is_recommended))

pdata <- pdata %>%
    group_by(is_recommended) %>%
    mutate(csum = cumsum(recomendation_count)) %>%
    mutate(percent = csum/sum(recomendation_count))

pdata <- pdata %>%
    filter(percent < 0.5) %>%
    group_by(is_recommended) %>%
    summarise(
        n = length(hours),
        mean_hours = mean(hours),
        sd = sd(hours)
    )

pdata <- pdata %>%
    group_by(is_recommended) %>%
    mutate(se = sd/sqrt(n)) %>%
    mutate(lower = mean_hours + qnorm(0.025) * se) %>%
    mutate(upper = mean_hours + qnorm(0.975) * se) %>%
    mutate(t_lower = mean_hours - qt(1 - alpha/2, n - 1) * se) %>%
    mutate(t_upper = mean_hours + qt(1 - alpha/2, n - 1) * se) %>%
    select(-c(se,sd))

knitr::kable(pdata, "simple")
```

Щодо даних довірчих інтервалів можна сказати лиш одне,
асимптотичний довірчий інтервал не сильно відрізняється від t-розподілу.

-   **Яка середня ціна гри по кожному із рейтингів**

Обрахуємо довірчий інтервал для середніх, що мають **нормальний розподіл**.

```{r, echo = FALSE, eval = TRUE}
alpha <- 0.05

pdata <- data %>% distinct(app_id, .keep_all = TRUE) %>% select(price_original, rating)
pdata <- pdata %>%
    group_by(rating) %>%
    summarise(
        mean_price = mean(price_original),
        n = length(price_original),
        sd = sd(price_original)
    )

pdata <- pdata %>%
    group_by(rating) %>%
    mutate(se = sd/sqrt(n)) %>%
    mutate(lower = mean_price + qnorm(0.025) * se) %>%
    mutate(upper = mean_price + qnorm(0.975) * se) %>%
    mutate(t_lower = mean_price - qt(1 - alpha/2, n - 1) * se) %>%
    mutate(t_upper = mean_price + qt(1 - alpha/2, n - 1) * se) %>%
    select(-c(se,sd))

knitr::kable(pdata, "simple")
```

З приводу даних довірчих інтервалів варто відзначити, що:

- При великій к-сті даних одбидва довірчих інтервали схожі (t-розпподіл, та асимптотичний)
- При малій к-сті даних інтервал побудовний t-розподілом є трохи кращим, так як він чітко вказує, що цим вимірам не точні.


Обрахуємо також 1,3 квартилі та їх довірчі інтервали. Застосуємо **бутстреп**.

```{r, echo = FALSE, eval = TRUE}
get_1st_quartile <- function(data, index) {
  return(quantile(data[index], 0.25))
}
get_3rd_quartile <- function(data, index) {
  return(quantile(data[index], 0.75))
}

B <- 1000

pdata <- data %>% distinct(app_id, .keep_all = TRUE) %>% select(price_original, rating)

pdata <- pdata %>%
    group_by(rating) %>%
    summarise(
        n = length(price_original),
        quartile_1 = boot.ci(boot(price_original, statistic = get_1st_quartile, R=B), type="perc")$t0,
        quartile_1_lower = boot.ci(boot(price_original, statistic = get_1st_quartile, R=B), type="perc")$percent[4],
        quartile_1_upper = boot.ci(boot(price_original, statistic = get_1st_quartile, R=B), type="perc")$percent[5],
        quartile_3 = boot.ci(boot(price_original, statistic = get_3rd_quartile, R=B), type="perc")$t0,
        quartile_3_lower = boot.ci(boot(price_original, statistic = get_3rd_quartile, R=B), type="perc")$percent[4],
        quartile_3_upper = boot.ci(boot(price_original, statistic = get_3rd_quartile, R=B), type="perc")$percent[5]
    )

knitr::kable(pdata, "simple")
```

З приводу даних довірчих інтервалів можна додати лиш те, що інтервали є досить великими.

-   **Чи змінює початкову вартість гри підтримка Mac, Linux (native)**

Обрахуємо довірчий інтервал для середніх, що мають **нормальний розподіл**.

```{r, message = FALSE, echo = FALSE, eval = TRUE}
alpha <- 0.05

pdata <- data %>% distinct(app_id, .keep_all = TRUE)

pdata$winonly <- ifelse(pdata$mac | pdata$linux, FALSE, TRUE)

pdata <- pdata %>%
    group_by(winonly) %>%
    summarise(
        mean_price = mean(price_original),
        n = length(price_original),
        sd = sd(price_original)
    )

pdata <- pdata %>%
    group_by(winonly) %>%
    mutate(se = sd/sqrt(n)) %>%
    mutate(lower = mean_price + qnorm(0.025) * se) %>%
    mutate(upper = mean_price + qnorm(0.975) * se) %>%
    mutate(t_lower = mean_price - qt(1 - alpha/2, n - 1) * se) %>%
    mutate(t_upper = mean_price + qt(1 - alpha/2, n - 1) * se) %>%
    select(-c(se,sd))

knitr::kable(pdata, "simple")
```

\newpage

-   **Залежність між рейтингом та ціною з високою знижкою**

Коефіцієнт кореляції не має нормального розподілу, тому будем використовувати **бутстреп**

```{r, echo = FALSE, eval = TRUE}
boot_cor_with_sd <- function(X, indices, estimate_var = TRUE){
  cor_bar <- cor(X[indices, ])[1, 2]

  if (estimate_var){
    boot_out <- boot(X[indices, ], statistic = boot_cor_with_sd, R = 200, estimate_var = FALSE)

    return(c(cor_bar, var(boot_out$t[, 1])))
  }
  else {
    return(cor_bar)
  }
}

B <- 2000

pdata <- data %>%
    distinct(app_id, .keep_all = TRUE) %>%
    select(positive_ratio, price_final, discount) %>%
    arrange(discount) %>%
    filter(discount > 0)

quartile_3rd <- quantile(pdata$discount)[4]

pdata <- pdata %>% filter(discount >= quartile_3rd) %>% select(price_final, positive_ratio)

boot_result_cor <- boot(pdata, statistic = boot_cor_with_sd, R = B, estimate_var = FALSE)

normal <- boot.ci(boot_result_cor, type = "norm")
basic <- boot.ci(boot_result_cor, type = "basic")
percentile <- boot.ci(boot_result_cor, type = "perc")

print("Normal confidence interval:")
print(normal)
print("Basic confidence interval:")
print(basic)
print("Percentile confidence interval:")
print(percentile)
```

Всі обраховані варіанти бутстрепу дали +- один і той самий результат.
З приводу самого результату можна вказати декілька фактів:

- Довірчий інтервал знаходиться строго лівіше від нуля (< 0)
- Гіпотеза про зв'язок фінальної ціни з високою знижкою та низьким рейтингом підтверджується
- Варто відзначити те, що інтервал є досить великим. (на мою думку це через те, що на рейтинг впливає не тільки і не скільки фінальна ціна а щось інше)

\newpage


-   **Зв'язок між кількістю рев'ю користувача і їх корисністю**

Коефіцієнт кореляції не має нормального розподілу, тому будем використовувати **бутстреп**

```{r, echo = FALSE, fig.cap = "Розподіли рев'ю та користності", eval = TRUE}
boot_cor_with_sd <- function(X, indices, estimate_var = TRUE){
  cor_bar <- cor(X[indices, ])[1, 2]

  if (estimate_var){
    boot_out <- boot(X[indices, ], statistic = boot_cor_with_sd, R = 200, estimate_var = FALSE)

    return(c(cor_bar, var(boot_out$t[, 1])))
  }
  else {
    return(cor_bar)
  }
}

B <- 2000

usertb <- data %>%
    group_by(user_id) %>%
    summarise(helpfullness = sum(helpful))

reviewtb <- data %>%
    distinct(user_id, .keep_all = TRUE) %>%
    select(user_id, reviews)

pdata <- inner_join(usertb, reviewtb, by="user_id")
pdata <- pdata %>% select(-c(user_id))

pdata <- pdata %>%
    filter(helpfullness > 0) %>%
    filter(reviews > 0)

boot_result_cor <- boot(pdata, statistic = boot_cor_with_sd, R = B, estimate_var = FALSE)

normal <- boot.ci(boot_result_cor, type = "norm")
basic <- boot.ci(boot_result_cor, type = "basic")
percentile <- boot.ci(boot_result_cor, type = "perc")

print("Normal confidence interval:")
print(normal)
print("Basic confidence interval:")
print(basic)
print("Percentile confidence interval:")
print(percentile)
```

Зв'язок є статистично значущим, однак незначним. Тому початкову гіпотезу можна відкинути.

\newpage


-   **Зв'язок між кумедністю рев'ю та його корисністю**

Коефіцієнт кореляції не має нормального розподілу, тому будем використовувати **бутстреп**

```{r, echo = FALSE, eval = TRUE}
boot_cor_with_sd <- function(X, indices, estimate_var = TRUE){
  cor_bar <- cor(X[indices, ])[1, 2]

  if (estimate_var){
    boot_out <- boot(X[indices, ], statistic = boot_cor_with_sd, R = 200, estimate_var = FALSE)

    return(c(cor_bar, var(boot_out$t[, 1])))
  }
  else {
    return(cor_bar)
  }
}

B <- 2000

pdata <- data %>%
    group_by(user_id) %>%
    summarise(
        helpful = sum(helpful),
        funny = sum(funny)
    ) %>%
    select(-user_id) %>%
    filter(funny > 0) %>%
    filter(helpful > 0)

boot_result_cor <- boot(pdata, statistic = boot_cor_with_sd, R = B, estimate_var = FALSE)

normal <- boot.ci(boot_result_cor, type = "norm")
basic <- boot.ci(boot_result_cor, type = "basic")
percentile <- boot.ci(boot_result_cor, type = "perc")

print("Normal confidence interval:")
print(normal)
print("Basic confidence interval:")
print(basic)
print("Percentile confidence interval:")
print(percentile)
```

Зв'язок є статистично значущим і є значним. Початкова гіпотеза підтверджується.

\newpage


## Тестування гіпотез

-   **В сердньому 50% негативних рев'ю можуть збиратися швидше ніж позитивні**

Протестуємо гіпотезу:

- H0: negative_meanhours - positive_meanhours >= 0
- H1: negative_meanhours - positive_meanhours < 0

```{r, message = FALSE, echo = FALSE, eval = TRUE}
alpha <- 0.05

pdata <- data %>% group_by(hours, is_recommended) %>%
    summarise(recomendation_count = length(is_recommended))

pdata <- pdata %>%
    group_by(is_recommended) %>%
    mutate(csum = cumsum(recomendation_count)) %>%
    mutate(percent = csum/sum(recomendation_count))

pdata <- pdata %>%
    filter(percent < 0.5)

t.test(hours ~ is_recommended, data = pdata, alternative="less")
```

Можна відкинути початкову H0.
Тобто в середньому 50% негативних рев'ю набирається за меншу к-сть ігрових годин ніж позитивних.

\newpage


-   **Підтримка додаткових платформ `Mac` та `Linux (native)` скоріше за все не змінює вартість гри**

Протестуємо гіпотезу:

- H0: win_meanprice - nonwin_meanprice >= 0
- H1: win_meanprice - nonwin_meanprice < 0

```{r, message = FALSE, echo = FALSE, eval = TRUE}
pdata <- data %>% distinct(app_id, .keep_all = TRUE)

pdata$winonly <- ifelse(pdata$mac | pdata$linux, FALSE, TRUE)

t.test(price_original ~ winonly, data = pdata, alternative="less")
```

Можна відкинути початкову H0.
Тобто підтримка `Mac` та/або `Linux (native)` не змінює (не збільшує) ціну гри в порівнянні з `Windows`.

\newpage


## Висновки cтатистичного виведення

На основі проведеного розвідкового аналізу можна зробити наступні висновки::

- Було уточнено наступні питання:
    - За скільки ігрових годин в сердньому набирається перших 50% рев'ю (позитивних/негативних).
    - Яка середня ціна гри по кожному із рейтингів.
- Підтврджено гіпотези:
    - Ціни із високими знижками скоріше за все сприяють зменшенню рейтингу.
    - Скоріше за все зв'язок між кумедністю та корисністю рев'ю - прямий (вища кумедність = вища корисність).
    - Підтримка додаткових платформ `Mac` та `Linux (native)` скоріше за все не змінює вартість гри.
    - В сердньому 50% негативних рев'ю можуть збираються швидше ніж позитивні.
- Спростовані гіпотези:
    - Можливо велика к-сть рев'ю може мати позитивний вплив на середню корисність рев'ю певного користувача.



# Лабораторна №3 -- Регресійний аналіз --

## Вступ

Для регресійного аналізу необхідна досить таки велика к-сть різних факторів.
Саме тому буде проведено регресійний аналіз над іграми (із окремого __[датасету](https://huggingface.co/datasets/FronkonGames/steam-games-dataset/viewer/FronkonGames--steam-games-dataset/train)__).
Також варто зауважити що у цьому датасеті ~70 000 записів, тому аналіз буде проведено не у 2020-2022 а по всіх роках. (на відміну від попереднього датасету тут десь на 20 000 ігор більше).

__Life is life and life never goes as planned.__

```{r, data_import_2, include = FALSE}
rm(data); gc();
data <- read_csv(
        "data/games_meta.csv",
        col_names = c("app_id","title","date_release","estimated_owners","peak_ccu",
                     "required_age","price","dlc_count","x_about_game","text_languages",
                     "audio_languages","x_reviews","x_header_image","x_website","x_support_url",
                     "x_support_email","windows","mac","linux","metacritic_score","x_metacritic_url",
                     "user_score","positive","negative","x_score_rank","achievements","recommendations",
                     "x_notes","average_playtime_forever","average_playtime_two_weeks","median_playtime_forever",
                     "median_playtime_two_weeks","x_developers","x_publishers","categories",
                     "genres","tags","x_screenshots","x_movies"),
        col_select = c("app_id","title","date_release","estimated_owners","peak_ccu","required_age","price",
                      "dlc_count","text_languages", "audio_languages","windows","mac","linux",
                      "metacritic_score","user_score","positive","negative","achievements","recommendations",
                      "average_playtime_forever","average_playtime_two_weeks","median_playtime_forever",
                      "median_playtime_two_weeks","categories","genres","tags"),
        skip = 1,
    )
```

### Підготовка даних

- Зконвертовано дати в правильний формат
- Уніфіковано вигляд nested колонок (наприклад tags)
- Перероблено `estimated_owners` ("0 - 1000" => 1000)
- Відфільтровано ігри у яких не зазнчаений середній час гри

```{r}
glimpse(data)
data$date_release <- as.Date(data$date_release, format = "%b %d, %y")
data <- data %>%
    rowwise() %>%
    mutate(
        text_languages = str_replace_all(text_languages, "[\\[\\]' ]", ""),
        audio_languages = str_replace_all(audio_languages, "[\\[\\]' ]", ""),
        estimated_owners = as.integer(str_match(estimated_owners, "([0-9]+) - ([0-9]+)")[3])
    ) %>%
    mutate(
        text_languages_count = str_count(text_languages, "([A-Za-z]+)"),
        audio_languages_count = str_count(audio_languages, "([A-Za-z]+)"),
        positive_ratio = ifelse(positive+negative == 0, 0, positive/(positive + negative))
    )
data <- data %>%
    select(
        estimated_owners, price, median_playtime_forever,
        dlc_count, text_languages_count, audio_languages_count, positive_ratio
    )
data %>% summary
```

### Викиди

```{r, echo = FALSE, eval = TRUE}
data  %>% pull(estimated_owners) %>% qqnorm(main = "Estimated owners qq plot")
data  %>% pull(price) %>% qqnorm(main = "Price qq plot")
data  %>% pull(median_playtime_forever) %>% qqnorm(main = "Median playtime qq plot")
```

```{r, echo = FALSE, message = FALSE}
data <- data %>%
    filter(estimated_owners < 1e7) %>%
    filter(price < 90) %>%
    filter(median_playtime_forever < 5000)
```

## Моделювання

**Чи збільшення ціни збільшує медіанний час гри?**

1) Залежною змінною медіана ігрових годин, а незалежною ціна.

2) Логаритми будуть застосовані до ціни (price).

3) OVB

- Оскільки медіана ігрових годин явно залежить не тільки від ціни то буде присутнє OVB
- Для мінімізації OVB потрібно буде ввести контрольні змінні
- На медіанний час гри в цілому може впливати наступний набір факторів:
    - Ціна
    - Популярність гри
    - Суб'єктивна оцінка гри гравцями
    - Підтримка різних мов доступність гри
    - Підтримка гри після випуску
- Контрольні змінні (наявні в датасеті):
    1. Приблизна к-сть власників гри (популярність)
    2. Відношення позитивних відгуків до всіх відгуків
    3. К-сть мов які підтримує гра в текстовому/аудіо форматі
    4. К-сть доповнень (підтримка гри після випуску)
- Гіпотези по коефіцієнтам біля контрольних змінних та їх OVB:
    1. Додатній, великий вплив
    2. Додатній, значний вплив
    3. Додатній, незначний вплив
    4. Додатній, незначний вплив

```{r, message = FALSE, echo = FALSE, eval = TRUE}
data <- data %>%
    filter(median_playtime_forever > 0) %>%
    filter(price > 0)

data %>% summary
data$estimated_owners <- as.factor(data$estimated_owners)

l1_model <- lm(median_playtime_forever ~ I(log(price)), data = data)
l1_model_hc2 <- coeftest(l1_model, vcov. = hccm(l1_model, type="hc2"))

l2_model <- lm(median_playtime_forever ~ I(log(price)) + estimated_owners, data = data)
l2_model_hc2 <- coeftest(l2_model, vcov. = hccm(l2_model, type="hc2"))

l3_model <- lm(median_playtime_forever ~ I(log(price)) + estimated_owners + dlc_count, data = data)
l3_model_hc2 <- coeftest(l3_model, vcov. = hccm(l3_model, type="hc2"))

l4_model <- lm(median_playtime_forever ~ I(log(price)) + estimated_owners + dlc_count + text_languages_count + audio_languages_count, data = data)
l4_model_hc2 <- coeftest(l4_model, vcov. = hccm(l4_model, type="hc2"))

l5_model <- lm(median_playtime_forever ~ I(log(price)) + estimated_owners + dlc_count + positive_ratio, data = data)
l5_model_hc2 <- coeftest(l5_model, vcov. = hccm(l5_model, type="hc2"))

stargazer(
    l1_model, l2_model, l3_model,l4_model,l5_model,
    type = "text",
    se = list(l1_model_hc2[,2],l2_model_hc2[,2],l3_model_hc2[,2],l4_model_hc2[,2],l5_model_hc2[,2]),
    no.space = TRUE,
    omit.stat = c("rsq", "f", "ser"),
    digits = 3
)
```

Із наведеної вище моделі можна зробити наступні висновки:

- Контрольні змінні, які стосувались локалізації виявились статистично незначущими (і не дивно)
- OVB було мінімізовано за допомогою наступних контрольних змінних:
    - Приблизна к-сть власників гри (популярність)
    - Відношення позитивних відгуків до всіх відгуків
    - К-сть доповнень (підтримка гри після випуску) (майже значуща)
- Контролюючи контрольні змінні можна говорити про причинно-наслідковий зв'язок.

## Перевірка моделі на стійкість

- Модель є лінійно-логаритмічною, то варто спробувати додати степені.

```{r, message = FALSE, echo = FALSE, eval = TRUE}
l1_model <- lm(median_playtime_forever ~ I(log(price)) + estimated_owners + positive_ratio, data = data)
l1_model_hc2 <- coeftest(l1_model, vcov. = hccm(l1_model, type="hc2"))

l2_model <- lm(median_playtime_forever ~ I(log(price)) + I(log(price)^2) + estimated_owners + positive_ratio, data = data)
l2_model_hc2 <- coeftest(l2_model, vcov. = hccm(l2_model, type="hc2"))

l3_model <- lm(median_playtime_forever ~ I(log(price)) + I(log(price)^2) + I(log(price)^3) + estimated_owners + positive_ratio, data = data)
l3_model_hc2 <- coeftest(l3_model, vcov. = hccm(l3_model, type="hc2"))

stargazer(
    l1_model, l2_model, l3_model,
    type = "text",
    se = list(l1_model_hc2[,2],l2_model_hc2[,2],l3_model_hc2[,2]),
    no.space = TRUE,
    omit.stat = c("rsq", "f", "ser"),
    digits = 3
)

ggplot(data, aes(x = I(log(price)), y = median_playtime_forever)) +
    geom_point() +
    labs(x = "Log(Price)", y = "Median in-game minutes") +
    geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "green") +
    geom_smooth(method = "lm", formula = y ~ x + I(x^2), se = FALSE, color = "blue") +
    geom_smooth(method = "lm", formula = y ~ x + I(x^2) + I(x^3), se = FALSE, color = "red")
```


## Оцінювання моделей

### Інтерпретація кофеіцієнтів

Розглянемо ціну (єдиний ключовий регресор).
Всі коефіцієнти біля даного регресора є статистично значущими.

Наведемо зміну ціни з 10 до 11 доларів:

- Для лінійної моделі зміна ціни (price) на 10% = збільшенню медіани на 11.23 хв
- Для квадратичної моделі зміна ціни на 10% = збільшенню медіани на 19.29 хв
- Для кубічної моделі зміна ціни на 10% = збільшенню медіани на 14.78 хв

### Статистична значущість груп коефііцієнтів

- Розглянемо значущість категорії estimated_owners

```{r, message = FALSE, echo = FALSE, eval = TRUE}
linearHypothesis(l3_model,
    c("estimated_owners50000 = 0", "estimated_owners100000 = 0",
      "estimated_owners200000 = 0", "estimated_owners500000 = 0",
      "estimated_owners1000000 = 0", "estimated_owners2000000 = 0",
      "estimated_owners5000000 = 0"),
    vcov = hccm(l3_model, type="hc2")
)
```

Відкидаємо гіпотезу про рівність

- Розглянемо значущість степеней логаритму

```{r, message = FALSE, echo = FALSE, eval = TRUE}
linearHypothesis(l3_model,
    c("I(log(price)^2) = 0", "I(log(price)^3) = 0"),
    vcov = hccm(l3_model, type="hc2")
)
```

Відкидаємо гіпотезу про рівність


