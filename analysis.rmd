---
title: "Аналіз рекомендацій в Steam"
author: "Скороденко Дмитро"
header-includes:
    - \usepackage{fontspec}
    - \usepackage{polyglossia}
    - \setmainlanguage{ukrainian}
    - \setotherlanguage{english}
    - \newfontfamily{\cyrillicfont}{Iosevka}
    - \newfontfamily{\cyrillicfonttt}{Iosevka}
    - \newfontfamily{\cyrillicfontsf}{Iosevka}
output:
    pdf_document:
        latex_engine: xelatex
---

```{r, setup, include = FALSE}
library(tidyverse)
library(GGally)
library(fastqq)
library(boot)
```

# Лабораторна №0 -- Вибір датасету --

Для проведення аналізу даних було обрано [датасет](https://www.kaggle.com/datasets/antonkozyriev/game-recommendations-on-steam),
який містить 10M+ записів про рекомендації комп'ютерних ігор користувачів платформи [Steam](https://store.steampowered.com/).
Оскільки в цьому датасеті зібрано дані про ігри які були випущені з 1997 по 2023 рік,
то його розмір не дасть змогу провести нормальний аналіз,
тому аналіз буде проводитись над іграми, які були випущені у 2020 - 2022 роках.

## Питання для дослідження:

1) За скільки ігрових годин в сердньому набирається перших 50% рев'ю (позитивних/негативних).
2) Яка середня ціна гри по кожному із рейтингів.
3) Залежність між рейтингом та цінами із високими знижками.
4) Зв'язок між кількістю рев'ю користувача і їх корисністю.
5) Зв'язок між кумедністю рев'ю та його корисністю.
6) Чи змінює початкову вартість гри підтримка `Mac`, `Linux (native)`.

## Гіпотези по дослідницьким питанням:

3) Ціни із високими знижками скоріше за все сприяють зменшенню рейтингу.
4) Можливо велика к-сть рев'ю може мати позитивний вплив на середню корисність рев'ю певного користувача.
5) Скоріше за все зв'язок між кумедністю та корисністю рев'ю - прямий (вища кумедність = вища корисність).
6) Підтримка додаткових платформ `Mac` та `Linux (native)` скоріше за все не змінює вартість гри.

## Короткий опис датасету:

Датасет містить 4 файли, далі наведено короткий опис кодного з них:

-   _games.csv_
    -   **app_id** - ід гри
    -   **title** - назва гри
    -   **date_release** - дата випуску гри
    -   **win** - підтримка гри на `Windows`
    -   **mac** - підтримка гри на `Mac`
    -   **linux** - підтримка гри на `Linux (native)`
    -   **rating** - рейтинг гри
    -   **positive_ratio** - відношення позитивних відгуків до всіх відгуків (у відсотках)
    -   **user_reviews** - кількість відгуків
    -   **price_final** - ціна зі знижками
    -   **price_original** - ціна при випускі гри
    -   **discount** - знижка (у відсотках)
    -   **steam_deck** - підтримка гри на `Steam Deck`
-   _recomendations.csv_
    -   **app_id** - ід гри
    -   **helpful** - к-сть користувачів, які сказали що рекомендація корисна
    -   **funny** - к-сть користувачів, які сказали що рекомендація дотепна
    -   **date** - дата публікації рекомендації
    -   **is_recommended** - чи рекомендує користувач дану гру
    -   **hours** - к-сть годин проведених у грі
    -   **user_id** - ід користувача
    -   **review_id** - ід рев'ю
-   _users.csv_
    -   **user_id** - ід користувача
    -   **products** - кількість куплених продуктів на платформі `Steam`
    -   **reviews** - к-сть рев'ю, які написав користувач
-   _games_metadata.json_
    -   Файл, що містить метаданні (теги, к-сть DLC ...). При аналізі даних використовуватись не буде

# Лабораторна №1 -- EDA --

```{r, data_import, include = FALSE}
games <- read_csv("data/games.csv")
recomendations <- read_csv("data/recommendations.csv")
users <- read_csv("data/users.csv")
```

## Підготовка даних

Дані в вибраному датасеті поділені на файли `users.csv`, `games.csv` та `recomendations.csv`. Остання є таблицею для зв'язку many to many. Для того щоб проводити подальшу роботу всі дані будуть об'єднані в одну таблицю.

```{r, table_join}
data <- inner_join(recomendations, games, by="app_id")
data <- inner_join(data, users, by="user_id")

rm(recomendations)
rm(games)
rm(users)

glimpse(data)
```

Далі відфільтруємо ігри які були випущені у 2020 - 2022 році.

```{r}
data <- data %>% filter(date_release > '2020-01-01')
data <- data %>% filter(date_release < '2023-01-01')
glimpse(data)
```

Далі перевіримо дані на `na`.

```{r}
data %>% is.na %>% colSums()
```

Датасет чистий.

Далі буде доцільно перекодувати колонку `rating`. Дані про кодування взято [тут](https://www.gamedeveloper.com/business/fixing-steam-s-user-rating-charts).

```{r}
rating <- case_match(
    data$rating,
    "Overwhelmingly Negative" ~ -4,
    "Very Negative" ~ -3,
    "Negative" ~ -2,
    "Mostly Negative" ~ -1,
    "Mixed" ~ 0,
    "Mostly Positive" ~ 1,
    "Positive" ~ 2,
    "Very Positive" ~ 3,
    "Overwhelmingly Positive" ~ 4
)
tmp <- tibble(rating = rating)
data <- data %>% select(-rating) %>% bind_cols(tmp)
data$rating %>% head(n=10)
```

Також можна прибрати колонку `title`, так як нас не цікавить назва гри, та змінити тип даних у деяких числових колонках.

```{r}
data <- data %>% select(-c(title))

data <- data %>%
    mutate(
        app_id = as.integer(app_id),
        user_id = as.integer(user_id),
        review_id = as.integer(review_id),
        helpful = as.integer(helpful),
        funny = as.integer(funny),
        user_reviews = as.integer(user_reviews),
        discount = as.integer(discount),
        products = as.integer(products),
        reviews = as.integer(reviews),
        rating = as.integer(rating),
        positive_ratio = as.integer(positive_ratio)
    )
```


\newpage

## Огляд числових характеристик

Оскільки початковий датасет включав зв'язок many to many, то огляд числових характеристик буде проводитись окремо для кожної сутності (`app`, `user`, `review`)

```{r}
data %>% distinct(app_id, .keep_all = TRUE) %>%
    select(
        app_id, date_release,
        rating, positive_ratio,
        user_reviews, price_final,
        price_original, discount,
        win, mac, linux, steam_deck
    ) %>%
    summary
```

```{r}
data %>% distinct(user_id, .keep_all = TRUE) %>%
    select(
        user_id, products,
        reviews
    ) %>%
    summary
```

```{r}
data %>% distinct(review_id, .keep_all = TRUE) %>%
    select(
        review_id, helpful, funny,
        date, hours, is_recommended
    ) %>%
    summary
```


\newpage

### Викиди

Очевидними кандидатами на перевірку викидів є `helpful`, `funny` та `products`.

```{r, echo = FALSE, eval = TRUE}
data  %>% distinct(review_id, .keep_all = TRUE) %>% pull(helpful) %>% qqnorm(main = "Helpful qq plot")
data  %>% distinct(app_id, .keep_all = TRUE)  %>% pull(funny) %>% qqnorm(main = "Funny qq plot")
data  %>% distinct(user_id, .keep_all = TRUE) %>% pull(products) %>% qqnorm(main = "Products qq plot")
```

У `funny` та `helpful` є викиди. Тому варто позбавитись їх.

```{r, echo = FALSE, message = FALSE}
data <- data %>%
    filter(funny < 500) %>%
    filter(helpful < 17000)
```


\newpage

## Аналіз даних

-   **За скільки ігрових годин в сердньому набирається перших 50% рев'ю (позитивних/негативних)**

Для початку варто побудувати фацетовані графіки ігрових годин і кількостей позитивних/негативних рекомендацій.

```{r, message = FALSE, echo = FALSE, fig.cap = "Рекомендації відносно ігрових годин та виду реакції", eval = TRUE}
pdata <- data %>% group_by(hours, is_recommended) %>%
    summarise(recomendation_count = length(is_recommended))

pdata <- pdata %>%
    group_by(is_recommended) %>%
    mutate(csum = cumsum(recomendation_count)) %>%
    mutate(percent = csum/sum(recomendation_count))

ldata <- pdata %>%
    filter(percent < 0.5) %>%
    group_by(is_recommended) %>%
    summarise(
        mean_hours = mean(hours),
        critical_point = max(hours)
    )

pdata <- pdata %>%
    mutate_at(vars(matches("recomendation_count")), log)

ggplot(pdata, aes(x = hours, y = recomendation_count)) +
    geom_point(size = 0.05) +
    geom_vline(aes(xintercept = critical_point), ldata, colour="red") +
    labs(x = "In-game hours", y = "Log(Recomendation count)") +
    facet_wrap(~is_recommended, labeller = as_labeller(c("TRUE" = "Recomends", "FALSE" = "Not recomends")))
```

Стосовно даного графіку можна вказати 3 факти:

- В перші ігрові години ставиться багато рекомендацій (як позитивних так і негативних)
- В середньому навть на 1000-их годинах позитивниі рекомендації ставлять часто, а для негативних реакцій це рідкість.
- Для того щоб набрати 50% всіх рекомендацій знадобилось в середньому:

```{r, echo = FALSE, eval = TRUE}
knitr::kable(ldata, "simple")
```


\newpage

-   **Яка середня ціна гри по кожному із рейтингів**

Зообразимо розподіл ціни (`price_original`) відносно оціночних категорій (`rating`)

```{r, echo = FALSE, fig.cap = "Розподіл цін відносно оціночних категорій", eval = TRUE}
pdata <- data %>% distinct(app_id, .keep_all = TRUE) %>% select(price_original, rating)

ldata <- pdata %>%
    group_by(rating) %>%
    summarise(mean(price_original), n = length(price_original))

pdata$factor <- factor(x = pdata$rating,
                       levels = c(-4,-3,-2,-1,0,1,2,3,4))

ggplot(pdata, aes(x = factor, y = price_original)) +
    geom_boxplot() +
    labs(x = "Game rating", y = "Original price")
```

Категорії рейтингу лежать в межах інтервалу [-4,4], де 4 - це найвища оцінка.
Середні значення наведені далі:

```{r, echo = FALSE, eval = TRUE}
knitr::kable(ldata, "simple")
```


\newpage

-   **Залежність між рейтингом та ціною з високою знижкою**

Нанесемо на грфік відсоток позитивних відгуків (`positive_ratio`), фінальну ціну (`price_final`) та знижку (`discount`).
Також варто зазначити що величина `positive_ratio` напряму зв'язана з `rating`, однак остання є дискретною,
а на даному графіку краще неперевна величина.

Оскільки початкова гіпотеза вказує на те що високі знижки - ознака поганої гри,
знижки будуть відфільтровані відносно 3 квартилю.

```{r, echo = FALSE, fig.cap = "Відсоток позитивних відгуків відносно знижки та фінальної ціни", eval = TRUE}
pdata <- data %>%
    distinct(app_id, .keep_all = TRUE) %>%
    select(positive_ratio, price_final, discount) %>%
    arrange(discount) %>%
    filter(discount > 0)

quartile_3rd <- quantile(pdata$discount)[4]

pdata <- pdata %>% filter(discount >= quartile_3rd)

ggplot(pdata, aes(x = price_final, y = positive_ratio)) +
    geom_point(alpha=0.5) +
    geom_smooth(method=lm, color="red", se=TRUE) +
    labs(x = "Final price", y = "Positive ratio")
```

Даний графік чітко показує, що дане дослідне пиитання не є безпідставним.
Більша частина знижок знаходиться вище 70% позитивних відгуків.

Обрахуємо коефіцієнт кореляції

```{r, eval = TRUE}
coef <- cor(pdata$price_final, pdata$positive_ratio)
knitr::kable(coef, "simple")
```

Коефіцієнт кореляції від'ємний - тобто зв'язок є.
Початкову гіпотезу не відкидаєм.


\newpage

-   **Зв'язок між кількістю рев'ю користувача і їх корисністю**

Нанесемо на графік рев'ю (`reviews`) та ln корисністі (`helpfullness`) відносно кожного окремого користувача (`users`).

```{r, echo = FALSE, fig.cap = "Розподіли рев'ю та користності", eval = TRUE}
usertb <- data %>%
    group_by(user_id) %>%
    summarise(helpfullness = sum(helpful))

reviewtb <- data %>%
    distinct(user_id, .keep_all = TRUE) %>%
    select(user_id, reviews)

pdata <- inner_join(usertb, reviewtb, by="user_id")
pdata <- pdata %>% select(-c(user_id))

pdata <- pdata %>%
    filter(helpfullness > 0) %>%
    filter(reviews > 0)

coef <- cor(pdata$reviews, pdata$helpfullness)

pdata <- pdata %>%
    mutate_at(vars(matches("helpfullness")), log) %>%
    arrange(reviews)

ggplot(pdata, aes(x = reviews, y = helpfullness)) +
    geom_point(alpha=0.1) +
    xlab("User reviews") +
    ylab("Ln(helpfullness)")

knitr::kable(coef, "simple")
```

На графіку видно, що `reviews` та `ln(helpfullness)` не мають чіткої взаємодії.
Коефіцієнт кореляції != 0, тому питання потребує уточнення.


\newpage

-   **Зв'язок між кумедністю рев'ю та його корисністю**

Оскільки початкова гіпотеза вказує на прямий зв'язок між кумедністю та корисністю.
Просто обрахуємо коефіцієнт кореляції.

```{r, echo = FALSE, eval = TRUE}
pdata <- data %>%
    group_by(user_id) %>%
    summarise(
        helpful = sum(helpful),
        funny = sum(funny)
    )

coef <- cor(pdata$helpful, pdata$funny)
knitr::kable(coef, "simple")
```

Коефіцієнт кореляції > 0.5.
Початкову гіпотезу не відкидаєм.


\newpage

-   **Чи змінює підтримка гри на Mac, Linux (native) початкову вартість гри**

Спочатку важливо зрозуміти співвідношення між різними платформами. Варто зазначити, що є ще одна платформа `Steam Deck`, але вона фактично запускає ті самі ігри що і `Windows`.

```{r, echo = FALSE, fig.cap = "Співідношення між платформами", eval = TRUE}
pdata <- data %>%
    distinct(app_id, .keep_all = TRUE) %>%
    summarise(win = sum(win), mac = sum(mac), linux = sum(linux))

pie(
    c(pdata$win, pdata$mac, pdata$linux),
    labels = c("Windows", "Mac", "Linux (native)")
)
```

Так як доля `Linux (native)` + `Mac` майже чверть від усіх ігор на `Windows`,
то побудуємо гістограми розподілу цін.

\newpage

Будть розглянуті ціни відносно `Linux (native)` та/або `Mac`.

```{r, message = FALSE, echo = FALSE, fig.cap = "Ціна відносно платформи", eval = TRUE}
pdata <- data %>% distinct(app_id, .keep_all = TRUE)

pdata$winonly <- ifelse(pdata$mac | pdata$linux, FALSE, TRUE)

ggplot(pdata, aes(x=price_original, fill=winonly)) +
    geom_histogram(alpha=0.5, position = 'identity') +
    scale_fill_manual(values=c("#69b3a2", "#404080")) +
    labs(x="Price", y="Count")
```

Судячи із графіків в цілому ціни на ігри на `Mac` та/або `Linux (native)` як мінімум не перевищюють ціну гри на `Windows`.
Початкову гіпотезу не відкидаєм.


\newpage

## Висновки EDA

На основі проведеного розвідкового аналізу можна зробити наступні висновки:

- Всі дослідницькі питання залишаються актуальними.
    - Початкові дослідницькі питання що потребують уточнення:
        - За скільки ігрових годин в сердньому набирається перших 50% рев'ю (позитивних/негативних).
        - Яка середня ціна гри по кожному із рейтингів.
    - Початкові гіпотези, що потребують подальшого розгляду:
        - Можливо велика к-сть рев'ю може мати позитивний вплив на середню корисність рев'ю певного користувача.
        - Ціни із високими знижками скоріше за все сприяють зменшенню рейтингу.
        - Скоріше за все зв'язок між кумедністю та корисністю рев'ю - прямий (вища кумедність = вища корисність).
        - Підтримка додаткових платформ `Mac` та `Linux (native)` скоріше за все не змінює вартість гри.
    - Гіпотези після проведення EDA:
        - В сердньому 50% негативних рев'ю можуть збираються швидше ніж позитивні.
- Головним обмеженням даного аналізу є великий розмір датасету, однак використання спецальних бібліотек типу `fastqq` непогано вирішує це питання навіть без додаткованих обцислюючих потужностей.


\newpage

# Лабораторна №2 -- Статистичне виведення --

Далі всі уточнюючі обчислення будуть згруповані відносно відповідних дослідних питань.

```{r, message = FALSE, echo = FALSE, eval = TRUE}
options(pillar.sigfig = 8)
```

## Довірчі інтервали

-   **За скільки ігрових годин в сердньому набирається перших 50% рев'ю (позитивних/негативних)**

Обрахуємо довірчий інтервал для середніх, що мають **нормальний розподіл**.

```{r, message = FALSE, echo = FALSE, eval = TRUE}
alpha <- 0.05

pdata <- data %>% group_by(hours, is_recommended) %>%
    summarise(recomendation_count = length(is_recommended))

pdata <- pdata %>%
    group_by(is_recommended) %>%
    mutate(csum = cumsum(recomendation_count)) %>%
    mutate(percent = csum/sum(recomendation_count))

pdata <- pdata %>%
    filter(percent < 0.5) %>%
    group_by(is_recommended) %>%
    summarise(
        n = length(hours),
        mean_hours = mean(hours),
        sd = sd(hours)
    )

pdata <- pdata %>%
    group_by(is_recommended) %>%
    mutate(se = sd/sqrt(n)) %>%
    mutate(lower = mean_hours + qnorm(0.025) * se) %>%
    mutate(upper = mean_hours + qnorm(0.975) * se) %>%
    mutate(t_lower = mean_hours - qt(1 - alpha/2, n - 1) * se) %>%
    mutate(t_upper = mean_hours + qt(1 - alpha/2, n - 1) * se) %>%
    select(-c(se,sd))

knitr::kable(pdata, "simple")
```

Щодо даних довірчих інтервалів можна сказати лиш одне,
асимптотичний довірчий інтервал не сильно відрізняється від t-розподілу.

-   **Яка середня ціна гри по кожному із рейтингів**

Обрахуємо довірчий інтервал для середніх, що мають **нормальний розподіл**.

```{r, echo = FALSE, eval = TRUE}
alpha <- 0.05

pdata <- data %>% distinct(app_id, .keep_all = TRUE) %>% select(price_original, rating)
pdata <- pdata %>%
    group_by(rating) %>%
    summarise(
        mean_price = mean(price_original),
        n = length(price_original),
        sd = sd(price_original)
    )

pdata <- pdata %>%
    group_by(rating) %>%
    mutate(se = sd/sqrt(n)) %>%
    mutate(lower = mean_price + qnorm(0.025) * se) %>%
    mutate(upper = mean_price + qnorm(0.975) * se) %>%
    mutate(t_lower = mean_price - qt(1 - alpha/2, n - 1) * se) %>%
    mutate(t_upper = mean_price + qt(1 - alpha/2, n - 1) * se) %>%
    select(-c(se,sd))

knitr::kable(pdata, "simple")
```

З приводу даних довірчих інтервалів варто відзначити, що:

- При великій к-сті даних одбидва довірчих інтервали схожі (t-розпподіл, та асимптотичний)
- При малій к-сті даних інтервал побудовний t-розподілом є трохи кращим, так як він чітко вказує, що цим вимірам не точні.


Обрахуємо також 1,3 квартилі та їх довірчі інтервали. Застосуємо **бутстреп**.

```{r, echo = FALSE, eval = TRUE}
get_1st_quartile <- function(data, index) {
  return(quantile(data[index], 0.25))
}
get_3rd_quartile <- function(data, index) {
  return(quantile(data[index], 0.75))
}

B <- 1000

pdata <- data %>% distinct(app_id, .keep_all = TRUE) %>% select(price_original, rating)

pdata <- pdata %>%
    group_by(rating) %>%
    summarise(
        n = length(price_original),
        quartile_1 = boot.ci(boot(price_original, statistic = get_1st_quartile, R=B), type="perc")$t0,
        quartile_1_lower = boot.ci(boot(price_original, statistic = get_1st_quartile, R=B), type="perc")$percent[4],
        quartile_1_upper = boot.ci(boot(price_original, statistic = get_1st_quartile, R=B), type="perc")$percent[5],
        quartile_3 = boot.ci(boot(price_original, statistic = get_3rd_quartile, R=B), type="perc")$t0,
        quartile_3_lower = boot.ci(boot(price_original, statistic = get_3rd_quartile, R=B), type="perc")$percent[4],
        quartile_3_upper = boot.ci(boot(price_original, statistic = get_3rd_quartile, R=B), type="perc")$percent[5]
    )

knitr::kable(pdata, "simple")
```

З приводу даних довірчих інтервалів можна додати лиш те, що інтервали є досить великими.

-   **Чи змінює початкову вартість гри підтримка Mac, Linux (native)**

Обрахуємо довірчий інтервал для середніх, що мають **нормальний розподіл**.

```{r, message = FALSE, echo = FALSE, eval = TRUE}
alpha <- 0.05

pdata <- data %>% distinct(app_id, .keep_all = TRUE)

pdata$winonly <- ifelse(pdata$mac | pdata$linux, FALSE, TRUE)

pdata <- pdata %>%
    group_by(winonly) %>%
    summarise(
        mean_price = mean(price_original),
        n = length(price_original),
        sd = sd(price_original)
    )

pdata <- pdata %>%
    group_by(winonly) %>%
    mutate(se = sd/sqrt(n)) %>%
    mutate(lower = mean_price + qnorm(0.025) * se) %>%
    mutate(upper = mean_price + qnorm(0.975) * se) %>%
    mutate(t_lower = mean_price - qt(1 - alpha/2, n - 1) * se) %>%
    mutate(t_upper = mean_price + qt(1 - alpha/2, n - 1) * se) %>%
    select(-c(se,sd))

knitr::kable(pdata, "simple")
```

\newpage

-   **Залежність між рейтингом та ціною з високою знижкою**

Коефіцієнт кореляції не має нормального розподілу, тому будем використовувати **бутстреп**

```{r, echo = FALSE, eval = TRUE}
boot_cor_with_sd <- function(X, indices, estimate_var = TRUE){
  cor_bar <- cor(X[indices, ])[1, 2]

  if (estimate_var){
    boot_out <- boot(X[indices, ], statistic = boot_cor_with_sd, R = 200, estimate_var = FALSE)

    return(c(cor_bar, var(boot_out$t[, 1])))
  }
  else {
    return(cor_bar)
  }
}

B <- 2000

pdata <- data %>%
    distinct(app_id, .keep_all = TRUE) %>%
    select(positive_ratio, price_final, discount) %>%
    arrange(discount) %>%
    filter(discount > 0)

quartile_3rd <- quantile(pdata$discount)[4]

pdata <- pdata %>% filter(discount >= quartile_3rd) %>% select(price_final, positive_ratio)

boot_result_cor <- boot(pdata, statistic = boot_cor_with_sd, R = B, estimate_var = FALSE)

normal <- boot.ci(boot_result_cor, type = "norm")
basic <- boot.ci(boot_result_cor, type = "basic")
percentile <- boot.ci(boot_result_cor, type = "perc")

print("Normal confidence interval:")
print(normal)
print("Basic confidence interval:")
print(basic)
print("Percentile confidence interval:")
print(percentile)
```

Всі обраховані варіанти бутстрепу дали +- один і той самий результат.
З приводу самого результату можна вказати декілька фактів:

- Довірчий інтервал знаходиться строго лівіше від нуля (< 0)
- Гіпотеза про зв'язок фінальної ціни з високою знижкою та низьким рейтингом підтверджується
- Варто відзначити те, що інтервал є досить великим. (на мою думку це через те, що на рейтинг впливає не тільки і не скільки фінальна ціна а щось інше)

\newpage


-   **Зв'язок між кількістю рев'ю користувача і їх корисністю**

Коефіцієнт кореляції не має нормального розподілу, тому будем використовувати **бутстреп**

```{r, echo = FALSE, fig.cap = "Розподіли рев'ю та користності", eval = TRUE}
boot_cor_with_sd <- function(X, indices, estimate_var = TRUE){
  cor_bar <- cor(X[indices, ])[1, 2]

  if (estimate_var){
    boot_out <- boot(X[indices, ], statistic = boot_cor_with_sd, R = 200, estimate_var = FALSE)

    return(c(cor_bar, var(boot_out$t[, 1])))
  }
  else {
    return(cor_bar)
  }
}

B <- 2000

usertb <- data %>%
    group_by(user_id) %>%
    summarise(helpfullness = sum(helpful))

reviewtb <- data %>%
    distinct(user_id, .keep_all = TRUE) %>%
    select(user_id, reviews)

pdata <- inner_join(usertb, reviewtb, by="user_id")
pdata <- pdata %>% select(-c(user_id))

pdata <- pdata %>%
    filter(helpfullness > 0) %>%
    filter(reviews > 0)

boot_result_cor <- boot(pdata, statistic = boot_cor_with_sd, R = B, estimate_var = FALSE)

normal <- boot.ci(boot_result_cor, type = "norm")
basic <- boot.ci(boot_result_cor, type = "basic")
percentile <- boot.ci(boot_result_cor, type = "perc")

print("Normal confidence interval:")
print(normal)
print("Basic confidence interval:")
print(basic)
print("Percentile confidence interval:")
print(percentile)
```

Зв'язок є статистично значущим, однак незначним. Тому початкову гіпотезу можна відкинути.

\newpage


-   **Зв'язок між кумедністю рев'ю та його корисністю**

Коефіцієнт кореляції не має нормального розподілу, тому будем використовувати **бутстреп**

```{r, echo = FALSE, eval = TRUE}
boot_cor_with_sd <- function(X, indices, estimate_var = TRUE){
  cor_bar <- cor(X[indices, ])[1, 2]

  if (estimate_var){
    boot_out <- boot(X[indices, ], statistic = boot_cor_with_sd, R = 200, estimate_var = FALSE)

    return(c(cor_bar, var(boot_out$t[, 1])))
  }
  else {
    return(cor_bar)
  }
}

B <- 2000

pdata <- data %>%
    group_by(user_id) %>%
    summarise(
        helpful = sum(helpful),
        funny = sum(funny)
    ) %>%
    select(-user_id) %>%
    filter(funny > 0) %>%
    filter(helpful > 0)

boot_result_cor <- boot(pdata, statistic = boot_cor_with_sd, R = B, estimate_var = FALSE)

normal <- boot.ci(boot_result_cor, type = "norm")
basic <- boot.ci(boot_result_cor, type = "basic")
percentile <- boot.ci(boot_result_cor, type = "perc")

print("Normal confidence interval:")
print(normal)
print("Basic confidence interval:")
print(basic)
print("Percentile confidence interval:")
print(percentile)
```

Зв'язок є статистично значущим і є значним. Початкова гіпотеза підтверджується.

\newpage


## Тестування гіпотез

-   **В сердньому 50% негативних рев'ю можуть збиратися швидше ніж позитивні**

Протестуємо гіпотезу:

- H0: negative_meanhours - positive_meanhours >= 0
- H1: negative_meanhours - positive_meanhours < 0

```{r, message = FALSE, echo = FALSE, eval = TRUE}
alpha <- 0.05

pdata <- data %>% group_by(hours, is_recommended) %>%
    summarise(recomendation_count = length(is_recommended))

pdata <- pdata %>%
    group_by(is_recommended) %>%
    mutate(csum = cumsum(recomendation_count)) %>%
    mutate(percent = csum/sum(recomendation_count))

pdata <- pdata %>%
    filter(percent < 0.5)

t.test(hours ~ is_recommended, data = pdata, alternative="less")
```

Можна відкинути початкову H0.
Тобто в середньому 50% негативних рев'ю набирається за меншу к-сть ігрових годин ніж позитивних.

\newpage


-   **Підтримка додаткових платформ `Mac` та `Linux (native)` скоріше за все не змінює вартість гри**

Протестуємо гіпотезу:

- H0: win_meanprice - nonwin_meanprice >= 0
- H1: win_meanprice - nonwin_meanprice < 0

```{r, message = FALSE, echo = FALSE, eval = TRUE}
pdata <- data %>% distinct(app_id, .keep_all = TRUE)

pdata$winonly <- ifelse(pdata$mac | pdata$linux, FALSE, TRUE)

t.test(price_original ~ winonly, data = pdata, alternative="less")
```

Можна відкинути початкову H0.
Тобто підтримка `Mac` та/або `Linux (native)` не змінює (не збільшує) ціну гри в порівнянні з `Windows`.

\newpage


## Висновки cтатистичного виведення

На основі проведеного розвідкового аналізу можна зробити наступні висновки::

- Було уточнено наступні питання:
    - За скільки ігрових годин в сердньому набирається перших 50% рев'ю (позитивних/негативних).
    - Яка середня ціна гри по кожному із рейтингів.
- Підтврджено гіпотези:
    - Ціни із високими знижками скоріше за все сприяють зменшенню рейтингу.
    - Скоріше за все зв'язок між кумедністю та корисністю рев'ю - прямий (вища кумедність = вища корисність).
    - Підтримка додаткових платформ `Mac` та `Linux (native)` скоріше за все не змінює вартість гри.
    - В сердньому 50% негативних рев'ю можуть збираються швидше ніж позитивні.
- Спростовані гіпотези:
    - Можливо велика к-сть рев'ю може мати позитивний вплив на середню корисність рев'ю певного користувача.
